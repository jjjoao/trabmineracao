import streamlit as st
import pandas as pd
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
import requests
import os

# --- CONFIGURA√á√ïES DA P√ÅGINA E FUN√á√ïES DE DOWNLOAD ---

st.set_page_config(
    page_title="Data App - Sa√∫de Mental",
    page_icon="üß†",
    layout="wide"
)

def download_file_from_google_drive(id, destination):
    """Fun√ß√£o robusta para baixar arquivos do Google Drive, lidando com avisos."""
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    response = session.get(URL, params={'id': id}, stream=True)
    token = None
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            token = value
            break
    if token:
        params = {'id': id, 'confirm': token}
        response = session.get(URL, params=params, stream=True)
    
    with open(destination, "wb") as f:
        for chunk in response.iter_content(32768):
            if chunk:
                f.write(chunk)

# --- CARREGAMENTO DO MODELO ---
MODEL_PATH = 'modelo_final (3).pkl'

@st.cache_resource
def load_model(model_path):
    """Carrega o modelo a partir de um arquivo local."""
    try:
        with open(model_path, 'rb') as file:
            model = pickle.load(file)
        return model
    except FileNotFoundError:
        st.error(f"Arquivo do modelo '{model_path}' n√£o encontrado. Certifique-se de que o nome est√° correto e que ele foi enviado para o reposit√≥rio do GitHub.")
        return None
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar o modelo: {e}")
        return None

model = load_model(MODEL_PATH)

# --- CARREGAMENTO DO DATASET PARA O DASHBOARD ---
DATASET_ID = '1ASanAI-8GIXbBsek87_WiaHQCM5FMRxA'
DATASET_PATH = 'mental_health.csv'

@st.cache_data
def load_data(file_id, dataset_path):
    """Baixa e carrega o dataset para o dashboard."""
    if not os.path.exists(dataset_path):
        st.info("Dataset n√£o encontrado. Baixando do Google Drive...")
        with st.spinner("Baixando dataset..."):
            download_file_from_google_drive(file_id, dataset_path)
            st.success("Download do dataset conclu√≠do!")
    try:
        return pd.read_csv(dataset_path)
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar o dataset: {e}")
        return None

# --- NAVEGA√á√ÉO E P√ÅGINAS ---
opcoes = ['Boas-vindas', 'Dashboard Interativo', 'Previs√£o de Interesse no Trabalho']
pagina = st.sidebar.selectbox('Navegue pelo menu:', opcoes)

# --- P√ÅGINA 1: BOAS-VINDAS ---
if pagina == 'Boas-vindas':
    st.title('**Data App de An√°lise de Sa√∫de Mental üß†**')
    st.header('Descri√ß√£o do Projeto e Metodologia')

    # Texto atualizado conforme solicitado
    st.markdown("""
        Este conjunto de dados parece conter uma variedade de recursos relacionados √† an√°lise de texto, an√°lise de sentimentos e indicadores psicol√≥gicos, provavelmente derivados de postagens ou dados de texto. Alguns recursos incluem √≠ndices de legibilidade, como o √çndice de Legibilidade Automatizado (ARI), o √çndice de Coleman Liau e o N√≠vel de Ensino Flesch-Kincaid, bem como pontua√ß√µes de an√°lise de sentimentos, como sentimentos compostos, negativos, neutros e positivos. Al√©m disso, h√° recursos relacionados a aspectos psicol√≥gicos, como estresse econ√¥mico, isolamento, uso de subst√¢ncias e estresse dom√©stico. O conjunto de dados parece abranger uma ampla gama de atributos lingu√≠sticos, psicol√≥gicos e comportamentais, potencialmente adequados para analisar t√≥picos relacionados √† sa√∫de mental em comunidades online ou dados de texto.

        O conjunto de dados fornece insights valiosos sobre sa√∫de mental, analisando padr√µes lingu√≠sticos, sentimentos e indicadores psicol√≥gicos em dados de texto. Pesquisadores e cientistas de dados podem obter uma melhor compreens√£o de como os problemas de sa√∫de mental se manifestam na comunica√ß√£o online.

        Com uma ampla gama de recursos, incluindo pontua√ß√µes de an√°lise de sentimentos e indicadores psicol√≥gicos, o conjunto de dados oferece oportunidades para o desenvolvimento de modelos preditivos para identificar ou prever resultados de sa√∫de mental com base em dados textuais.
    """)
    st.markdown("---")
    st.subheader("Constru√ß√£o do Modelo")
    st.markdown("""
        O modelo utilizado √© uma combina√ß√£o de dois modelos: um **Extreme Gradient Boosting** e um **Random Forest**.
        
        Inicialmente, foram removidos os indiv√≠duos que responderam "Maybe" para a vari√°vel de interesse `Work_Interest` para facilitar a constru√ß√£o do modelo, j√° que esses n√£o eram de interesse para o estudo. Foi realizado um pr√©-processamento dos dados, transformando todas as vari√°veis categ√≥ricas com *n* categorias em *n-1* vari√°veis, e uma separa√ß√£o dos dados entre treino e teste, sendo 70% para treino e 30% para teste. Al√©m disso, foram feitos 10 folds de valida√ß√£o cruzada com o conjunto de treino.
        
        Assim, foram comparados 15 modelos de machine learning atrav√©s das m√©tricas Acur√°cia, AUC, Recall, Precis√£o, F1-Score, Kappa e MCC. Os modelos de Random Forest e Extreme Gradient Boosting tiveram as melhores performances entre todos os outros em todas as m√©tricas.
        
        Dessa forma, foi utilizado o comando `tune_model`, que realizou 10 folds de valida√ß√£o cruzada para selecionar os melhores hiperpar√¢metros que maximizem o F1-score dos modelos. Finalmente, foi feita uma combina√ß√£o (ensemble) dos modelos otimizados, fazendo uma m√©dia das probabilidades preditas para determinar quais indiv√≠duos t√™m interesse no trabalho e quais n√£o t√™m.
        
        O modelo final foi testado nos 30% dos dados separados para teste, e as m√©tricas para a classifica√ß√£o do modelo foram:
    """)
    
    # Tabela de m√©tricas
    metrics_data = {
        'M√©trica': ['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa', 'MCC'],
        'Valor': [0.9995, 1.0000, 0.9988, 1.0000, 0.9994, 0.9989, 0.9989]
    }
    metrics_df = pd.DataFrame(metrics_data)
    st.table(metrics_df)


# --- P√ÅGINA 2: DASHBOARD INTERATIVO ---
elif pagina == 'Dashboard Interativo':
    st.header('Dashboard de An√°lise do Dataset')
    dados = load_data(DATASET_ID, DATASET_PATH)
    if dados is not None:
        st.write("Vis√£o geral dos dados brutos:")
        st.dataframe(dados.head())
        st.markdown('---')
        st.subheader("Filtros e M√©tricas")
        col1, col2, col3 = st.columns(3)
        genero = col1.selectbox("G√™nero", dados['Gender'].unique())
        hist_familiar = col2.selectbox("Hist√≥rico Familiar", dados['family_history'].unique())
        ocupacao = col3.selectbox("Ocupa√ß√£o", dados['Occupation'].unique())
        filtro = (dados['Gender'] == genero) & (dados['family_history'] == hist_familiar) & (dados['Occupation'] == ocupacao)
        dados_filtrados = dados[filtro]
        if dados_filtrados.empty:
            st.warning("Nenhum dado encontrado para a combina√ß√£o de filtros selecionada.")
        else:
            col1, col2 = st.columns([1, 2])
            with col1:
                st.metric('Indiv√≠duos na Sele√ß√£o', dados_filtrados.shape[0])
                mood_mode = dados_filtrados['Mood_Swings'].mode()[0]
                st.metric('Humor Mais Comum', mood_mode)
                st.metric('Procuraram Tratamento', '{:.2%}'.format(dados_filtrados['treatment'].value_counts(normalize=True).get('Yes', 0)))
            with col2:
                fig, ax = plt.subplots()
                sns.countplot(data=dados_filtrados, x='Work_Interest', ax=ax, palette='viridis')
                ax.set_title('Distribui√ß√£o de Interesse no Trabalho (Filtrado)')
                ax.set_xlabel('Interesse no Trabalho')
                ax.set_ylabel('Contagem')
                st.pyplot(fig)

